# Assignment8_CIFAR10
This project implements a Convolutuion NN model for CIFAR10 10 Class image classification.

## Project Structure

├── models/custom_models.py # Contains all variation of model architectures
├── train.py # Training script with data loading and training loops
├── data/ # Directory for CIFAR10 dataset
├── utils/transform.py # Directory for albumentation transformation

## Model Architecture

The model consists of 4 convolution blocks (C1, C2, C3, C4) with the following features:
- C1: Standard convolutions
- C2: Dilated convolutions 
- C3: Depthwise separable convolutions 
- C4: Standard convolutions 
- Global Average Pooling followed by FC layer (**GAP and FC**)
- Final Receptive Field: **59** ( Required> 44)
- No MaxPooling
- Less than 200k parameters (**Parameters - 198862**)

## Data Augmentation

 Albumentations library used :
    HorizontalFlip(p=0.5),
    ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=15, p=0.5),
    CoarseDropout(max_holes=1, max_height=16, max_width=16, min_holes=1, 
                       min_height=16, min_width=16, fill_value=[0.4914, 0.4822, 0.4465], p=0.5),
    Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2470, 0.2435, 0.2616]) CIFAR10 Mean and St Deviatiation
    
## Training Details

- **Optimizer**: SGD with lr(0.01) momentum (0.9) and weight decay (1e-4)
- **Learning Rate**: OneCycleLR scheduler
- **Batch Size**: 128
- **Epochs**: 200
- **Best Model** : best_model.pth
- **Test Accuracy**: **86.40%**

## Detail Model Log
----------------------------------------------------------------
Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 32, 32]             432
       BatchNorm2d-2           [-1, 16, 32, 32]              32
              ReLU-3           [-1, 16, 32, 32]               0
           Dropout-4           [-1, 16, 32, 32]               0
            Conv2d-5           [-1, 24, 32, 32]           3,456
       BatchNorm2d-6           [-1, 24, 32, 32]              48
              ReLU-7           [-1, 24, 32, 32]               0
           Dropout-8           [-1, 24, 32, 32]               0
            Conv2d-9           [-1, 32, 32, 32]           6,912
      BatchNorm2d-10           [-1, 32, 32, 32]              64
             ReLU-11           [-1, 32, 32, 32]               0
          Dropout-12           [-1, 32, 32, 32]               0
           Conv2d-13           [-1, 48, 32, 32]          13,824
      BatchNorm2d-14           [-1, 48, 32, 32]              96
             ReLU-15           [-1, 48, 32, 32]               0
          Dropout-16           [-1, 48, 32, 32]               0
           Conv2d-17           [-1, 48, 32, 32]             432
      BatchNorm2d-18           [-1, 48, 32, 32]              96
             ReLU-19           [-1, 48, 32, 32]               0
          Dropout-20           [-1, 48, 32, 32]               0
           Conv2d-21           [-1, 64, 32, 32]           3,072
      BatchNorm2d-22           [-1, 64, 32, 32]             128
             ReLU-23           [-1, 64, 32, 32]               0
          Dropout-24           [-1, 64, 32, 32]               0
           Conv2d-25           [-1, 80, 32, 32]          46,080
      BatchNorm2d-26           [-1, 80, 32, 32]             160
             ReLU-27           [-1, 80, 32, 32]               0
          Dropout-28           [-1, 80, 32, 32]               0
           Conv2d-29           [-1, 90, 32, 32]          64,800
      BatchNorm2d-30           [-1, 90, 32, 32]             180
             ReLU-31           [-1, 90, 32, 32]               0
          Dropout-32           [-1, 90, 32, 32]               0
           Conv2d-33           [-1, 72, 32, 32]          58,320
           AdaptiveAvgPool2d-34  [-1, 72, 1, 1]               0
           Linear-35                   [-1, 10]             730
           
     Total params: 198,862
     Trainable params: 198,862
     Non-trainable params: 0
----------------------------------------------------------------
     Input size (MB): 0.01
     Forward/backward pass size (MB): 13.13
     Params size (MB): 0.76
     Estimated Total Size (MB): 13.90
----------------------------------------------------------------

Total Parameters: 198862
Epoch=1 Loss=1.6453 Batch_id=390 Accuracy=29.65 LR=0.004066: 100%|████████████████████████████████████████████████████████████| 391/391 [00:32<00:00, 12.13it/s] 

Test set: Average loss: 0.0139, Accuracy: 3868/10000 (38.68%)

Best accuracy: 38.68%
Epoch=2 Loss=1.5961 Batch_id=390 Accuracy=45.24 LR=0.004263: 100%|████████████████████████████████████████████████████████████| 391/391 [00:37<00:00, 10.31it/s] 

Test set: Average loss: 0.0110, Accuracy: 4985/10000 (49.85%)

Best accuracy: 49.85%
Epoch=3 Loss=1.4468 Batch_id=390 Accuracy=51.05 LR=0.004591: 100%|████████████████████████████████████████████████████████████| 391/391 [00:41<00:00,  9.37it/s] 

Test set: Average loss: 0.0096, Accuracy: 5748/10000 (57.48%)

Best accuracy: 57.48%
Epoch=4 Loss=1.1417 Batch_id=390 Accuracy=55.03 LR=0.005049: 100%|████████████████████████████████████████████████████████████| 391/391 [00:44<00:00,  8.72it/s] 

Test set: Average loss: 0.0091, Accuracy: 5807/10000 (58.07%)

Best accuracy: 58.07%
Epoch=5 Loss=1.0572 Batch_id=390 Accuracy=58.33 LR=0.005636: 100%|████████████████████████████████████████████████████████████| 391/391 [00:48<00:00,  8.02it/s] 

Test set: Average loss: 0.0111, Accuracy: 5634/10000 (56.34%)

Epoch=6 Loss=1.0081 Batch_id=390 Accuracy=60.14 LR=0.006349: 100%|████████████████████████████████████████████████████████████| 391/391 [00:49<00:00,  7.85it/s] 

Test set: Average loss: 0.0097, Accuracy: 6092/10000 (60.92%)

Best accuracy: 60.92%
Epoch=7 Loss=1.1305 Batch_id=390 Accuracy=61.94 LR=0.007188: 100%|████████████████████████████████████████████████████████████| 391/391 [00:47<00:00,  8.32it/s] 

Test set: Average loss: 0.0090, Accuracy: 6152/10000 (61.52%)

Best accuracy: 61.52%
Epoch=8 Loss=1.0206 Batch_id=390 Accuracy=63.02 LR=0.008150: 100%|████████████████████████████████████████████████████████████| 391/391 [00:43<00:00,  8.90it/s] 

Test set: Average loss: 0.0083, Accuracy: 6451/10000 (64.51%)

Best accuracy: 64.51%
Epoch=9 Loss=1.1736 Batch_id=390 Accuracy=64.22 LR=0.009232: 100%|████████████████████████████████████████████████████████████| 391/391 [00:41<00:00,  9.45it/s] 

Test set: Average loss: 0.0075, Accuracy: 6746/10000 (67.46%)

Best accuracy: 67.46%
Epoch=10 Loss=1.2017 Batch_id=390 Accuracy=64.83 LR=0.010431: 100%|███████████████████████████████████████████████████████████| 391/391 [00:37<00:00, 10.33it/s] 

Test set: Average loss: 0.0069, Accuracy: 7003/10000 (70.03%)

Best accuracy: 70.03%
Epoch=11 Loss=1.0481 Batch_id=390 Accuracy=65.78 LR=0.011744: 100%|███████████████████████████████████████████████████████████| 391/391 [00:34<00:00, 11.47it/s] 

Test set: Average loss: 0.0063, Accuracy: 7308/10000 (73.08%)

Best accuracy: 73.08%
Epoch=12 Loss=1.0906 Batch_id=390 Accuracy=66.46 LR=0.013168: 100%|███████████████████████████████████████████████████████████| 391/391 [00:32<00:00, 12.17it/s] 

Test set: Average loss: 0.0066, Accuracy: 7163/10000 (71.63%)

Epoch=13 Loss=0.9545 Batch_id=390 Accuracy=67.05 LR=0.014698: 100%|███████████████████████████████████████████████████████████| 391/391 [00:34<00:00, 11.38it/s] 

Test set: Average loss: 0.0073, Accuracy: 6940/10000 (69.40%)

Epoch=14 Loss=0.9949 Batch_id=390 Accuracy=67.20 LR=0.016330: 100%|███████████████████████████████████████████████████████████| 391/391 [00:39<00:00,  9.87it/s] 

Test set: Average loss: 0.0060, Accuracy: 7457/10000 (74.57%)

Best accuracy: 74.57%
Epoch=15 Loss=0.8351 Batch_id=390 Accuracy=68.21 LR=0.018060: 100%|███████████████████████████████████████████████████████████| 391/391 [00:41<00:00,  9.41it/s] 

Test set: Average loss: 0.0062, Accuracy: 7305/10000 (73.05%)

Epoch=16 Loss=0.9250 Batch_id=390 Accuracy=68.41 LR=0.019883: 100%|███████████████████████████████████████████████████████████| 391/391 [00:46<00:00,  8.44it/s] 

Test set: Average loss: 0.0065, Accuracy: 7267/10000 (72.67%)

Epoch=17 Loss=0.9478 Batch_id=390 Accuracy=68.68 LR=0.021794: 100%|███████████████████████████████████████████████████████████| 391/391 [00:49<00:00,  7.95it/s] 

Test set: Average loss: 0.0065, Accuracy: 7277/10000 (72.77%)

Epoch=18 Loss=0.9349 Batch_id=390 Accuracy=68.84 LR=0.023788: 100%|███████████████████████████████████████████████████████████| 391/391 [00:46<00:00,  8.42it/s] 

Test set: Average loss: 0.0064, Accuracy: 7375/10000 (73.75%)

Epoch=19 Loss=0.8968 Batch_id=390 Accuracy=69.47 LR=0.025859: 100%|███████████████████████████████████████████████████████████| 391/391 [00:43<00:00,  8.95it/s] 

Test set: Average loss: 0.0069, Accuracy: 7191/10000 (71.91%)

Epoch=20 Loss=0.7556 Batch_id=390 Accuracy=69.73 LR=0.028002: 100%|███████████████████████████████████████████████████████████| 391/391 [00:40<00:00,  9.72it/s] 

Test set: Average loss: 0.0064, Accuracy: 7343/10000 (73.43%)

Epoch=21 Loss=0.6440 Batch_id=390 Accuracy=69.79 LR=0.030210: 100%|███████████████████████████████████████████████████████████| 391/391 [00:36<00:00, 10.65it/s] 

Test set: Average loss: 0.0068, Accuracy: 7215/10000 (72.15%)

Epoch=22 Loss=0.8556 Batch_id=390 Accuracy=70.27 LR=0.032479: 100%|███████████████████████████████████████████████████████████| 391/391 [00:32<00:00, 11.95it/s] 

Test set: Average loss: 0.0057, Accuracy: 7639/10000 (76.39%)

Best accuracy: 76.39%
Epoch=23 Loss=0.8943 Batch_id=390 Accuracy=70.84 LR=0.034801: 100%|███████████████████████████████████████████████████████████| 391/391 [00:31<00:00, 12.23it/s] 

Test set: Average loss: 0.0077, Accuracy: 6974/10000 (69.74%)

Epoch=24 Loss=0.5766 Batch_id=390 Accuracy=70.88 LR=0.037170: 100%|███████████████████████████████████████████████████████████| 391/391 [00:35<00:00, 10.86it/s] 

Test set: Average loss: 0.0060, Accuracy: 7551/10000 (75.51%)

Epoch=25 Loss=0.8797 Batch_id=390 Accuracy=70.99 LR=0.039579: 100%|███████████████████████████████████████████████████████████| 391/391 [00:40<00:00,  9.58it/s] 

Test set: Average loss: 0.0056, Accuracy: 7680/10000 (76.80%)

Best accuracy: 76.80%
Epoch=26 Loss=0.7758 Batch_id=390 Accuracy=70.89 LR=0.042023: 100%|███████████████████████████████████████████████████████████| 391/391 [00:43<00:00,  8.95it/s] 

Test set: Average loss: 0.0060, Accuracy: 7485/10000 (74.85%)

Epoch=27 Loss=0.9595 Batch_id=390 Accuracy=71.33 LR=0.044494: 100%|███████████████████████████████████████████████████████████| 391/391 [00:48<00:00,  7.98it/s] 

Test set: Average loss: 0.0061, Accuracy: 7539/10000 (75.39%)

Epoch=28 Loss=0.6855 Batch_id=390 Accuracy=71.66 LR=0.046986: 100%|███████████████████████████████████████████████████████████| 391/391 [00:48<00:00,  8.06it/s] 

Test set: Average loss: 0.0060, Accuracy: 7622/10000 (76.22%)

Epoch=29 Loss=0.9080 Batch_id=390 Accuracy=71.85 LR=0.049491: 100%|███████████████████████████████████████████████████████████| 391/391 [00:45<00:00,  8.64it/s] 

Test set: Average loss: 0.0054, Accuracy: 7772/10000 (77.72%)

Best accuracy: 77.72%
Epoch=30 Loss=0.8182 Batch_id=390 Accuracy=72.14 LR=0.052003: 100%|███████████████████████████████████████████████████████████| 391/391 [00:43<00:00,  9.06it/s] 

Test set: Average loss: 0.0068, Accuracy: 7401/10000 (74.01%)

Epoch=31 Loss=1.1694 Batch_id=390 Accuracy=72.11 LR=0.054515: 100%|███████████████████████████████████████████████████████████| 391/391 [00:38<00:00, 10.28it/s] 

Test set: Average loss: 0.0050, Accuracy: 7838/10000 (78.38%)

Best accuracy: 78.38%
Epoch=32 Loss=0.6206 Batch_id=390 Accuracy=71.97 LR=0.057021: 100%|███████████████████████████████████████████████████████████| 391/391 [00:33<00:00, 11.51it/s] 

Test set: Average loss: 0.0057, Accuracy: 7720/10000 (77.20%)

Epoch=33 Loss=0.9182 Batch_id=390 Accuracy=72.34 LR=0.059512: 100%|███████████████████████████████████████████████████████████| 391/391 [00:31<00:00, 12.26it/s] 

Test set: Average loss: 0.0055, Accuracy: 7695/10000 (76.95%)

Epoch=34 Loss=0.9641 Batch_id=390 Accuracy=72.74 LR=0.061983: 100%|███████████████████████████████████████████████████████████| 391/391 [00:34<00:00, 11.32it/s] 

Test set: Average loss: 0.0065, Accuracy: 7444/10000 (74.44%)

Epoch=35 Loss=1.0407 Batch_id=390 Accuracy=72.71 LR=0.064427: 100%|███████████████████████████████████████████████████████████| 391/391 [00:40<00:00,  9.57it/s] 

Test set: Average loss: 0.0057, Accuracy: 7703/10000 (77.03%)

Epoch=36 Loss=0.6314 Batch_id=390 Accuracy=73.06 LR=0.066836: 100%|███████████████████████████████████████████████████████████| 391/391 [00:43<00:00,  9.09it/s] 

Test set: Average loss: 0.0052, Accuracy: 7864/10000 (78.64%)

Best accuracy: 78.64%
Epoch=37 Loss=0.6434 Batch_id=390 Accuracy=72.85 LR=0.069205: 100%|███████████████████████████████████████████████████████████| 391/391 [01:12<00:00,  5.42it/s] 

Test set: Average loss: 0.0061, Accuracy: 7603/10000 (76.03%)

Epoch=38 Loss=0.5388 Batch_id=390 Accuracy=73.11 LR=0.071527: 100%|███████████████████████████████████████████████████████████| 391/391 [01:09<00:00,  5.61it/s] 

Test set: Average loss: 0.0060, Accuracy: 7605/10000 (76.05%)

Epoch=39 Loss=0.7169 Batch_id=390 Accuracy=73.15 LR=0.073795: 100%|███████████████████████████████████████████████████████████| 391/391 [01:06<00:00,  5.84it/s] 

Test set: Average loss: 0.0071, Accuracy: 7281/10000 (72.81%)

Epoch=40 Loss=0.8263 Batch_id=390 Accuracy=73.13 LR=0.076004: 100%|███████████████████████████████████████████████████████████| 391/391 [01:10<00:00,  5.58it/s] 

Test set: Average loss: 0.0054, Accuracy: 7891/10000 (78.91%)

Best accuracy: 78.91%
Epoch=41 Loss=0.8931 Batch_id=390 Accuracy=73.32 LR=0.078146: 100%|███████████████████████████████████████████████████████████| 391/391 [01:06<00:00,  5.91it/s] 

Test set: Average loss: 0.0063, Accuracy: 7501/10000 (75.01%)

Epoch=42 Loss=0.7230 Batch_id=390 Accuracy=73.53 LR=0.080217: 100%|███████████████████████████████████████████████████████████| 391/391 [01:03<00:00,  6.19it/s] 

Test set: Average loss: 0.0059, Accuracy: 7695/10000 (76.95%)

Epoch=43 Loss=0.8222 Batch_id=390 Accuracy=73.42 LR=0.082211: 100%|███████████████████████████████████████████████████████████| 391/391 [01:02<00:00,  6.29it/s] 

Test set: Average loss: 0.0052, Accuracy: 7936/10000 (79.36%)

Best accuracy: 79.36%
Epoch=44 Loss=0.7054 Batch_id=390 Accuracy=73.59 LR=0.084122: 100%|███████████████████████████████████████████████████████████| 391/391 [01:02<00:00,  6.24it/s] 

Test set: Average loss: 0.0051, Accuracy: 7898/10000 (78.98%)

Epoch=45 Loss=0.6843 Batch_id=390 Accuracy=73.96 LR=0.085945: 100%|███████████████████████████████████████████████████████████| 391/391 [01:04<00:00,  6.08it/s]

Test set: Average loss: 0.0051, Accuracy: 7965/10000 (79.65%)

Best accuracy: 79.65%
Epoch=46 Loss=0.7712 Batch_id=390 Accuracy=73.90 LR=0.087674: 100%|███████████████████████████████████████████████████████████| 391/391 [01:04<00:00,  6.06it/s] 

Test set: Average loss: 0.0065, Accuracy: 7516/10000 (75.16%)

Epoch=47 Loss=0.7431 Batch_id=390 Accuracy=73.92 LR=0.089306: 100%|███████████████████████████████████████████████████████████| 391/391 [01:06<00:00,  5.88it/s] 

Test set: Average loss: 0.0058, Accuracy: 7716/10000 (77.16%)

Epoch=48 Loss=0.8007 Batch_id=390 Accuracy=73.85 LR=0.090836: 100%|███████████████████████████████████████████████████████████| 391/391 [01:12<00:00,  5.42it/s] 

Test set: Average loss: 0.0052, Accuracy: 7850/10000 (78.50%)

Epoch=49 Loss=0.7422 Batch_id=390 Accuracy=74.27 LR=0.092259: 100%|███████████████████████████████████████████████████████████| 391/391 [01:14<00:00,  5.24it/s] 

Test set: Average loss: 0.0076, Accuracy: 7351/10000 (73.51%)

Epoch=50 Loss=0.6036 Batch_id=390 Accuracy=74.04 LR=0.093572: 100%|███████████████████████████████████████████████████████████| 391/391 [01:17<00:00,  5.08it/s] 

Test set: Average loss: 0.0054, Accuracy: 7817/10000 (78.17%)

Epoch=51 Loss=0.7041 Batch_id=390 Accuracy=74.08 LR=0.094771: 100%|███████████████████████████████████████████████████████████| 391/391 [01:18<00:00,  4.97it/s] 

Test set: Average loss: 0.0055, Accuracy: 7800/10000 (78.00%)

Epoch=52 Loss=0.8786 Batch_id=390 Accuracy=74.10 LR=0.095852: 100%|███████████████████████████████████████████████████████████| 391/391 [01:16<00:00,  5.08it/s] 

Test set: Average loss: 0.0058, Accuracy: 7799/10000 (77.99%)

Epoch=53 Loss=0.8605 Batch_id=390 Accuracy=74.31 LR=0.096814: 100%|███████████████████████████████████████████████████████████| 391/391 [01:19<00:00,  4.91it/s] 

Test set: Average loss: 0.0054, Accuracy: 7930/10000 (79.30%)

Epoch=54 Loss=0.6307 Batch_id=390 Accuracy=74.45 LR=0.097653: 100%|███████████████████████████████████████████████████████████| 391/391 [01:18<00:00,  5.00it/s] 

Test set: Average loss: 0.0060, Accuracy: 7745/10000 (77.45%)

Epoch=55 Loss=0.6904 Batch_id=390 Accuracy=74.69 LR=0.098366: 100%|███████████████████████████████████████████████████████████| 391/391 [01:17<00:00,  5.02it/s] 

Test set: Average loss: 0.0055, Accuracy: 7789/10000 (77.89%)

Epoch=56 Loss=0.6060 Batch_id=390 Accuracy=74.47 LR=0.098952: 100%|███████████████████████████████████████████████████████████| 391/391 [01:17<00:00,  5.03it/s] 

Test set: Average loss: 0.0052, Accuracy: 7951/10000 (79.51%)

Epoch=57 Loss=0.8613 Batch_id=390 Accuracy=74.65 LR=0.099410: 100%|███████████████████████████████████████████████████████████| 391/391 [01:19<00:00,  4.94it/s] 

Test set: Average loss: 0.0057, Accuracy: 7800/10000 (78.00%)

Epoch=58 Loss=0.7383 Batch_id=390 Accuracy=74.42 LR=0.099738: 100%|███████████████████████████████████████████████████████████| 391/391 [02:18<00:00,  2.82it/s] 

Test set: Average loss: 0.0053, Accuracy: 7926/10000 (79.26%)

Epoch=59 Loss=0.7595 Batch_id=390 Accuracy=74.88 LR=0.099935: 100%|███████████████████████████████████████████████████████████| 391/391 [03:36<00:00,  1.80it/s] 

Test set: Average loss: 0.0061, Accuracy: 7749/10000 (77.49%)

Epoch=60 Loss=0.6472 Batch_id=390 Accuracy=74.47 LR=0.100000: 100%|███████████████████████████████████████████████████████████| 391/391 [03:43<00:00,  1.75it/s] 

Test set: Average loss: 0.0066, Accuracy: 7660/10000 (76.60%)

Epoch=61 Loss=0.7629 Batch_id=390 Accuracy=74.78 LR=0.099987: 100%|███████████████████████████████████████████████████████████| 391/391 [04:33<00:00,  1.43it/s] 

Test set: Average loss: 0.0058, Accuracy: 7816/10000 (78.16%)

Epoch=62 Loss=0.7875 Batch_id=390 Accuracy=75.11 LR=0.099950: 100%|███████████████████████████████████████████████████████████| 391/391 [04:57<00:00,  1.32it/s] 

Test set: Average loss: 0.0050, Accuracy: 8010/10000 (80.10%)

Best accuracy: 80.10%
Epoch=63 Loss=0.8326 Batch_id=390 Accuracy=75.03 LR=0.099887: 100%|███████████████████████████████████████████████████████████| 391/391 [05:00<00:00,  1.30it/s] 

Test set: Average loss: 0.0052, Accuracy: 7928/10000 (79.28%)

Epoch=64 Loss=0.8194 Batch_id=390 Accuracy=75.28 LR=0.099798: 100%|███████████████████████████████████████████████████████████| 391/391 [06:29<00:00,  1.00it/s] 

Test set: Average loss: 0.0051, Accuracy: 7999/10000 (79.99%)

Epoch=65 Loss=0.5853 Batch_id=390 Accuracy=74.98 LR=0.099685: 100%|█████████████████████████████████████████████████████████| 391/391 [6:21:42<00:00, 58.58s/it] 

Test set: Average loss: 0.0054, Accuracy: 7883/10000 (78.83%)

Epoch=66 Loss=0.5137 Batch_id=390 Accuracy=74.96 LR=0.099547: 100%|███████████████████████████████████████████████████████████| 391/391 [00:40<00:00,  9.62it/s] 

Test set: Average loss: 0.0054, Accuracy: 7959/10000 (79.59%)

Epoch=67 Loss=0.7452 Batch_id=390 Accuracy=75.30 LR=0.099384: 100%|███████████████████████████████████████████████████████████| 391/391 [00:36<00:00, 10.71it/s] 

Test set: Average loss: 0.0057, Accuracy: 7800/10000 (78.00%)

Epoch=68 Loss=0.6919 Batch_id=390 Accuracy=75.00 LR=0.099196: 100%|███████████████████████████████████████████████████████████| 391/391 [00:34<00:00, 11.41it/s] 

Test set: Average loss: 0.0054, Accuracy: 7966/10000 (79.66%)

Epoch=69 Loss=0.5797 Batch_id=390 Accuracy=75.03 LR=0.098983: 100%|███████████████████████████████████████████████████████████| 391/391 [00:33<00:00, 11.64it/s] 

Test set: Average loss: 0.0064, Accuracy: 7649/10000 (76.49%)

Epoch=70 Loss=0.5870 Batch_id=390 Accuracy=75.54 LR=0.098746: 100%|███████████████████████████████████████████████████████████| 391/391 [00:34<00:00, 11.22it/s] 

Test set: Average loss: 0.0061, Accuracy: 7742/10000 (77.42%)

Epoch=71 Loss=0.7156 Batch_id=390 Accuracy=75.18 LR=0.098484: 100%|███████████████████████████████████████████████████████████| 391/391 [00:40<00:00,  9.55it/s] 

Test set: Average loss: 0.0056, Accuracy: 7797/10000 (77.97%)

Epoch=72 Loss=0.8610 Batch_id=390 Accuracy=75.59 LR=0.098197: 100%|███████████████████████████████████████████████████████████| 391/391 [00:45<00:00,  8.66it/s] 

Test set: Average loss: 0.0057, Accuracy: 7885/10000 (78.85%)

Epoch=73 Loss=0.6688 Batch_id=390 Accuracy=75.35 LR=0.097887: 100%|███████████████████████████████████████████████████████████| 391/391 [00:49<00:00,  7.94it/s] 

Test set: Average loss: 0.0047, Accuracy: 8068/10000 (80.68%)

Best accuracy: 80.68%
Epoch=74 Loss=0.7853 Batch_id=390 Accuracy=75.71 LR=0.097552: 100%|███████████████████████████████████████████████████████████| 391/391 [00:49<00:00,  7.85it/s] 

Test set: Average loss: 0.0053, Accuracy: 8003/10000 (80.03%)

Epoch=75 Loss=0.6451 Batch_id=390 Accuracy=75.58 LR=0.097193: 100%|███████████████████████████████████████████████████████████| 391/391 [00:45<00:00,  8.52it/s] 

Test set: Average loss: 0.0054, Accuracy: 7976/10000 (79.76%)

Epoch=76 Loss=0.6253 Batch_id=390 Accuracy=75.37 LR=0.096811: 100%|███████████████████████████████████████████████████████████| 391/391 [00:43<00:00,  9.05it/s] 

Test set: Average loss: 0.0060, Accuracy: 7842/10000 (78.42%)

Epoch=77 Loss=0.6470 Batch_id=390 Accuracy=76.04 LR=0.096405: 100%|███████████████████████████████████████████████████████████| 391/391 [00:38<00:00, 10.08it/s] 

Test set: Average loss: 0.0054, Accuracy: 7919/10000 (79.19%)

Epoch=78 Loss=0.7707 Batch_id=390 Accuracy=75.49 LR=0.095975: 100%|███████████████████████████████████████████████████████████| 391/391 [00:34<00:00, 11.19it/s] 

Test set: Average loss: 0.0052, Accuracy: 8035/10000 (80.35%)

Epoch=79 Loss=0.7017 Batch_id=390 Accuracy=75.73 LR=0.095523: 100%|███████████████████████████████████████████████████████████| 391/391 [00:31<00:00, 12.37it/s] 

Test set: Average loss: 0.0050, Accuracy: 8039/10000 (80.39%)

Epoch=80 Loss=0.5419 Batch_id=390 Accuracy=75.79 LR=0.095047: 100%|███████████████████████████████████████████████████████████| 391/391 [00:33<00:00, 11.54it/s] 

Test set: Average loss: 0.0052, Accuracy: 8038/10000 (80.38%)

Epoch=81 Loss=0.5979 Batch_id=390 Accuracy=75.97 LR=0.094549: 100%|███████████████████████████████████████████████████████████| 391/391 [00:38<00:00, 10.26it/s] 

Test set: Average loss: 0.0056, Accuracy: 8014/10000 (80.14%)

Epoch=82 Loss=0.6859 Batch_id=390 Accuracy=75.83 LR=0.094028: 100%|███████████████████████████████████████████████████████████| 391/391 [00:41<00:00,  9.39it/s] 

Test set: Average loss: 0.0053, Accuracy: 8036/10000 (80.36%)

Epoch=83 Loss=0.6334 Batch_id=390 Accuracy=75.81 LR=0.093486: 100%|███████████████████████████████████████████████████████████| 391/391 [00:45<00:00,  8.58it/s] 

Test set: Average loss: 0.0058, Accuracy: 7850/10000 (78.50%)

Epoch=84 Loss=0.4403 Batch_id=390 Accuracy=76.02 LR=0.092921: 100%|███████████████████████████████████████████████████████████| 391/391 [00:49<00:00,  7.89it/s] 

Test set: Average loss: 0.0062, Accuracy: 7687/10000 (76.87%)

Epoch=85 Loss=0.6299 Batch_id=390 Accuracy=76.19 LR=0.092335: 100%|███████████████████████████████████████████████████████████| 391/391 [00:48<00:00,  7.99it/s] 

Test set: Average loss: 0.0046, Accuracy: 8194/10000 (81.94%)

Best accuracy: 81.94%
Epoch=86 Loss=0.5098 Batch_id=390 Accuracy=76.09 LR=0.091727: 100%|███████████████████████████████████████████████████████████| 391/391 [00:45<00:00,  8.61it/s] 

Test set: Average loss: 0.0054, Accuracy: 7992/10000 (79.92%)

Epoch=87 Loss=0.6204 Batch_id=390 Accuracy=76.08 LR=0.091099: 100%|███████████████████████████████████████████████████████████| 391/391 [00:42<00:00,  9.12it/s] 

Test set: Average loss: 0.0068, Accuracy: 7585/10000 (75.85%)

Epoch=88 Loss=0.6094 Batch_id=390 Accuracy=76.18 LR=0.090449: 100%|███████████████████████████████████████████████████████████| 391/391 [00:37<00:00, 10.30it/s] 

Test set: Average loss: 0.0051, Accuracy: 8019/10000 (80.19%)

Epoch=89 Loss=0.7732 Batch_id=390 Accuracy=75.74 LR=0.089780: 100%|███████████████████████████████████████████████████████████| 391/391 [00:33<00:00, 11.55it/s] 

Test set: Average loss: 0.0061, Accuracy: 7814/10000 (78.14%)

Epoch=90 Loss=0.4097 Batch_id=390 Accuracy=76.14 LR=0.089090: 100%|███████████████████████████████████████████████████████████| 391/391 [00:31<00:00, 12.28it/s] 

Test set: Average loss: 0.0050, Accuracy: 8081/10000 (80.81%)

Epoch=91 Loss=0.6430 Batch_id=390 Accuracy=76.45 LR=0.088380: 100%|███████████████████████████████████████████████████████████| 391/391 [00:35<00:00, 11.07it/s] 

Test set: Average loss: 0.0048, Accuracy: 8103/10000 (81.03%)

Epoch=92 Loss=0.6458 Batch_id=390 Accuracy=76.16 LR=0.087652: 100%|███████████████████████████████████████████████████████████| 391/391 [00:40<00:00,  9.61it/s] 

Test set: Average loss: 0.0060, Accuracy: 7801/10000 (78.01%)

Epoch=93 Loss=0.6983 Batch_id=390 Accuracy=76.36 LR=0.086904: 100%|███████████████████████████████████████████████████████████| 391/391 [00:42<00:00,  9.12it/s] 

Test set: Average loss: 0.0055, Accuracy: 7967/10000 (79.67%)

Epoch=94 Loss=0.7776 Batch_id=390 Accuracy=76.42 LR=0.086138: 100%|███████████████████████████████████████████████████████████| 391/391 [00:48<00:00,  8.03it/s] 

Test set: Average loss: 0.0058, Accuracy: 7949/10000 (79.49%)

Epoch=95 Loss=0.8050 Batch_id=390 Accuracy=76.18 LR=0.085353: 100%|███████████████████████████████████████████████████████████| 391/391 [00:49<00:00,  7.97it/s] 

Test set: Average loss: 0.0049, Accuracy: 8052/10000 (80.52%)

Epoch=96 Loss=0.6688 Batch_id=390 Accuracy=76.50 LR=0.084551: 100%|███████████████████████████████████████████████████████████| 391/391 [00:46<00:00,  8.44it/s] 

Test set: Average loss: 0.0046, Accuracy: 8208/10000 (82.08%)

Best accuracy: 82.08%
Epoch=97 Loss=0.7642 Batch_id=390 Accuracy=76.43 LR=0.083731: 100%|███████████████████████████████████████████████████████████| 391/391 [00:43<00:00,  9.02it/s] 

Test set: Average loss: 0.0053, Accuracy: 8060/10000 (80.60%)

Epoch=98 Loss=0.5935 Batch_id=390 Accuracy=76.24 LR=0.082895: 100%|███████████████████████████████████████████████████████████| 391/391 [00:38<00:00, 10.09it/s] 

Test set: Average loss: 0.0046, Accuracy: 8247/10000 (82.47%)

Best accuracy: 82.47%
Epoch=99 Loss=0.4981 Batch_id=390 Accuracy=76.46 LR=0.082042: 100%|███████████████████████████████████████████████████████████| 391/391 [00:34<00:00, 11.26it/s] 

Test set: Average loss: 0.0054, Accuracy: 8033/10000 (80.33%)

Epoch=100 Loss=0.7070 Batch_id=390 Accuracy=76.55 LR=0.081172: 100%|██████████████████████████████████████████████████████████| 391/391 [00:31<00:00, 12.25it/s] 

Test set: Average loss: 0.0059, Accuracy: 7768/10000 (77.68%)

Epoch=101 Loss=0.8138 Batch_id=390 Accuracy=76.55 LR=0.080287: 100%|██████████████████████████████████████████████████████████| 391/391 [00:33<00:00, 11.61it/s] 

Test set: Average loss: 0.0049, Accuracy: 8129/10000 (81.29%)

Epoch=102 Loss=0.6395 Batch_id=390 Accuracy=76.64 LR=0.079387: 100%|██████████████████████████████████████████████████████████| 391/391 [00:38<00:00, 10.07it/s] 

Test set: Average loss: 0.0056, Accuracy: 7934/10000 (79.34%)

Epoch=103 Loss=0.8477 Batch_id=390 Accuracy=76.89 LR=0.078472: 100%|██████████████████████████████████████████████████████████| 391/391 [00:41<00:00,  9.52it/s] 

Test set: Average loss: 0.0054, Accuracy: 7990/10000 (79.90%)

Epoch=104 Loss=0.6238 Batch_id=390 Accuracy=76.85 LR=0.077543: 100%|██████████████████████████████████████████████████████████| 391/391 [00:45<00:00,  8.53it/s] 

Test set: Average loss: 0.0051, Accuracy: 8128/10000 (81.28%)

Epoch=105 Loss=0.5582 Batch_id=390 Accuracy=76.70 LR=0.076599: 100%|██████████████████████████████████████████████████████████| 391/391 [00:49<00:00,  7.91it/s] 

Test set: Average loss: 0.0044, Accuracy: 8239/10000 (82.39%)

Epoch=106 Loss=0.5640 Batch_id=390 Accuracy=76.97 LR=0.075643: 100%|██████████████████████████████████████████████████████████| 391/391 [00:47<00:00,  8.15it/s] 

Test set: Average loss: 0.0050, Accuracy: 8102/10000 (81.02%)

Epoch=107 Loss=0.6092 Batch_id=390 Accuracy=76.88 LR=0.074673: 100%|██████████████████████████████████████████████████████████| 391/391 [00:44<00:00,  8.73it/s] 

Test set: Average loss: 0.0057, Accuracy: 7889/10000 (78.89%)

Epoch=108 Loss=0.6926 Batch_id=390 Accuracy=76.80 LR=0.073691: 100%|██████████████████████████████████████████████████████████| 391/391 [00:42<00:00,  9.22it/s] 

Test set: Average loss: 0.0055, Accuracy: 7950/10000 (79.50%)

Epoch=109 Loss=0.6102 Batch_id=390 Accuracy=77.24 LR=0.072697: 100%|██████████████████████████████████████████████████████████| 391/391 [00:38<00:00, 10.21it/s] 

Test set: Average loss: 0.0051, Accuracy: 8068/10000 (80.68%)

Epoch=110 Loss=0.7152 Batch_id=390 Accuracy=76.95 LR=0.071692: 100%|██████████████████████████████████████████████████████████| 391/391 [00:34<00:00, 11.46it/s] 

Test set: Average loss: 0.0047, Accuracy: 8181/10000 (81.81%)

Epoch=111 Loss=0.6420 Batch_id=390 Accuracy=77.12 LR=0.070675: 100%|██████████████████████████████████████████████████████████| 391/391 [00:31<00:00, 12.24it/s] 

Test set: Average loss: 0.0051, Accuracy: 8103/10000 (81.03%)

Epoch=112 Loss=0.5750 Batch_id=390 Accuracy=77.19 LR=0.069649: 100%|██████████████████████████████████████████████████████████| 391/391 [00:35<00:00, 11.05it/s] 

Test set: Average loss: 0.0058, Accuracy: 7978/10000 (79.78%)

Epoch=113 Loss=0.7999 Batch_id=390 Accuracy=77.03 LR=0.068612: 100%|██████████████████████████████████████████████████████████| 391/391 [00:40<00:00,  9.76it/s] 

Test set: Average loss: 0.0052, Accuracy: 8089/10000 (80.89%)

Epoch=114 Loss=0.6830 Batch_id=390 Accuracy=77.17 LR=0.067566: 100%|██████████████████████████████████████████████████████████| 391/391 [00:42<00:00,  9.14it/s] 

Test set: Average loss: 0.0044, Accuracy: 8239/10000 (82.39%)

Epoch=115 Loss=0.7716 Batch_id=390 Accuracy=77.26 LR=0.066511: 100%|██████████████████████████████████████████████████████████| 391/391 [00:47<00:00,  8.20it/s] 

Test set: Average loss: 0.0047, Accuracy: 8178/10000 (81.78%)

Epoch=116 Loss=0.6426 Batch_id=390 Accuracy=77.11 LR=0.065448: 100%|██████████████████████████████████████████████████████████| 391/391 [00:49<00:00,  7.93it/s] 

Test set: Average loss: 0.0055, Accuracy: 8006/10000 (80.06%)

Epoch=117 Loss=0.4966 Batch_id=390 Accuracy=77.29 LR=0.064377: 100%|██████████████████████████████████████████████████████████| 391/391 [00:46<00:00,  8.45it/s] 

Test set: Average loss: 0.0046, Accuracy: 8228/10000 (82.28%)

Epoch=118 Loss=0.5982 Batch_id=390 Accuracy=77.33 LR=0.063299: 100%|██████████████████████████████████████████████████████████| 391/391 [00:43<00:00,  9.03it/s] 

Test set: Average loss: 0.0050, Accuracy: 8155/10000 (81.55%)

Epoch=119 Loss=0.6604 Batch_id=390 Accuracy=77.45 LR=0.062214: 100%|██████████████████████████████████████████████████████████| 391/391 [00:39<00:00,  9.88it/s] 

Test set: Average loss: 0.0051, Accuracy: 8062/10000 (80.62%)

Epoch=120 Loss=0.5604 Batch_id=390 Accuracy=77.15 LR=0.061123: 100%|██████████████████████████████████████████████████████████| 391/391 [00:35<00:00, 10.96it/s] 

Test set: Average loss: 0.0043, Accuracy: 8315/10000 (83.15%)

Best accuracy: 83.15%
Epoch=121 Loss=0.5262 Batch_id=390 Accuracy=77.59 LR=0.060027: 100%|██████████████████████████████████████████████████████████| 391/391 [00:31<00:00, 12.28it/s] 

Test set: Average loss: 0.0045, Accuracy: 8275/10000 (82.75%)

Epoch=122 Loss=0.8467 Batch_id=390 Accuracy=77.66 LR=0.058925: 100%|██████████████████████████████████████████████████████████| 391/391 [00:32<00:00, 11.96it/s] 

Test set: Average loss: 0.0049, Accuracy: 8118/10000 (81.18%)

Epoch=123 Loss=0.7985 Batch_id=390 Accuracy=77.69 LR=0.057819: 100%|██████████████████████████████████████████████████████████| 391/391 [00:37<00:00, 10.43it/s] 

Test set: Average loss: 0.0047, Accuracy: 8198/10000 (81.98%)

Epoch=124 Loss=0.7406 Batch_id=390 Accuracy=77.86 LR=0.056709: 100%|██████████████████████████████████████████████████████████| 391/391 [00:41<00:00,  9.42it/s] 

Test set: Average loss: 0.0045, Accuracy: 8272/10000 (82.72%)

Epoch=125 Loss=0.7997 Batch_id=390 Accuracy=77.81 LR=0.055596: 100%|██████████████████████████████████████████████████████████| 391/391 [00:45<00:00,  8.63it/s] 

Test set: Average loss: 0.0047, Accuracy: 8250/10000 (82.50%)

Epoch=126 Loss=0.6611 Batch_id=390 Accuracy=77.59 LR=0.054479: 100%|██████████████████████████████████████████████████████████| 391/391 [00:49<00:00,  7.87it/s] 

Test set: Average loss: 0.0050, Accuracy: 8185/10000 (81.85%)

Epoch=127 Loss=0.6445 Batch_id=390 Accuracy=77.52 LR=0.053361: 100%|██████████████████████████████████████████████████████████| 391/391 [00:49<00:00,  7.94it/s] 

Test set: Average loss: 0.0047, Accuracy: 8190/10000 (81.90%)

Epoch=128 Loss=0.6415 Batch_id=390 Accuracy=77.92 LR=0.052241: 100%|██████████████████████████████████████████████████████████| 391/391 [00:45<00:00,  8.58it/s] 

Test set: Average loss: 0.0046, Accuracy: 8211/10000 (82.11%)

Epoch=129 Loss=0.5142 Batch_id=390 Accuracy=78.03 LR=0.051119: 100%|██████████████████████████████████████████████████████████| 391/391 [00:42<00:00,  9.11it/s] 

Test set: Average loss: 0.0048, Accuracy: 8239/10000 (82.39%)

Epoch=130 Loss=0.7013 Batch_id=390 Accuracy=78.09 LR=0.049997: 100%|██████████████████████████████████████████████████████████| 391/391 [00:37<00:00, 10.30it/s] 

Test set: Average loss: 0.0045, Accuracy: 8296/10000 (82.96%)

Epoch=131 Loss=0.5227 Batch_id=390 Accuracy=78.24 LR=0.048875: 100%|██████████████████████████████████████████████████████████| 391/391 [00:34<00:00, 11.28it/s] 

Test set: Average loss: 0.0045, Accuracy: 8208/10000 (82.08%)

Epoch=132 Loss=0.7160 Batch_id=390 Accuracy=78.10 LR=0.047754: 100%|██████████████████████████████████████████████████████████| 391/391 [00:32<00:00, 12.20it/s] 

Test set: Average loss: 0.0056, Accuracy: 7970/10000 (79.70%)

Epoch=133 Loss=0.6634 Batch_id=390 Accuracy=78.15 LR=0.046634: 100%|██████████████████████████████████████████████████████████| 391/391 [00:34<00:00, 11.43it/s] 

Test set: Average loss: 0.0048, Accuracy: 8180/10000 (81.80%)

Epoch=134 Loss=0.7117 Batch_id=390 Accuracy=77.80 LR=0.045515: 100%|██████████████████████████████████████████████████████████| 391/391 [00:39<00:00,  9.95it/s] 

Test set: Average loss: 0.0050, Accuracy: 8187/10000 (81.87%)

Epoch=135 Loss=0.6981 Batch_id=390 Accuracy=78.18 LR=0.044399: 100%|██████████████████████████████████████████████████████████| 391/391 [00:42<00:00,  9.28it/s] 

Test set: Average loss: 0.0050, Accuracy: 8154/10000 (81.54%)

Epoch=136 Loss=0.5970 Batch_id=390 Accuracy=78.12 LR=0.043286: 100%|██████████████████████████████████████████████████████████| 391/391 [00:45<00:00,  8.50it/s] 

Test set: Average loss: 0.0045, Accuracy: 8312/10000 (83.12%)

Epoch=137 Loss=0.5356 Batch_id=390 Accuracy=78.48 LR=0.042176: 100%|██████████████████████████████████████████████████████████| 391/391 [00:49<00:00,  7.94it/s] 

Test set: Average loss: 0.0051, Accuracy: 8167/10000 (81.67%)

Epoch=138 Loss=0.5342 Batch_id=390 Accuracy=78.40 LR=0.041070: 100%|██████████████████████████████████████████████████████████| 391/391 [00:48<00:00,  8.06it/s] 

Test set: Average loss: 0.0048, Accuracy: 8248/10000 (82.48%)

Epoch=139 Loss=0.5226 Batch_id=390 Accuracy=78.42 LR=0.039968: 100%|██████████████████████████████████████████████████████████| 391/391 [00:45<00:00,  8.60it/s] 

Test set: Average loss: 0.0047, Accuracy: 8228/10000 (82.28%)

Epoch=140 Loss=0.5491 Batch_id=390 Accuracy=78.31 LR=0.038871: 100%|██████████████████████████████████████████████████████████| 391/391 [00:42<00:00,  9.14it/s] 

Test set: Average loss: 0.0045, Accuracy: 8291/10000 (82.91%)

Epoch=141 Loss=0.6939 Batch_id=390 Accuracy=78.52 LR=0.037780: 100%|██████████████████████████████████████████████████████████| 391/391 [00:38<00:00, 10.03it/s] 

Test set: Average loss: 0.0044, Accuracy: 8309/10000 (83.09%)

Epoch=142 Loss=0.5519 Batch_id=390 Accuracy=79.08 LR=0.036696: 100%|██████████████████████████████████████████████████████████| 391/391 [00:35<00:00, 10.97it/s] 

Test set: Average loss: 0.0046, Accuracy: 8240/10000 (82.40%)

Epoch=143 Loss=0.6954 Batch_id=390 Accuracy=78.69 LR=0.035618: 100%|██████████████████████████████████████████████████████████| 391/391 [00:32<00:00, 12.07it/s] 

Test set: Average loss: 0.0054, Accuracy: 8046/10000 (80.46%)

Epoch=144 Loss=0.5194 Batch_id=390 Accuracy=78.97 LR=0.034547: 100%|██████████████████████████████████████████████████████████| 391/391 [00:31<00:00, 12.60it/s] 

Test set: Average loss: 0.0046, Accuracy: 8265/10000 (82.65%)

Epoch=145 Loss=0.6489 Batch_id=390 Accuracy=78.70 LR=0.033484: 100%|██████████████████████████████████████████████████████████| 391/391 [00:32<00:00, 11.92it/s] 

Test set: Average loss: 0.0049, Accuracy: 8140/10000 (81.40%)

Epoch=146 Loss=0.4435 Batch_id=390 Accuracy=78.98 LR=0.032429: 100%|██████████████████████████████████████████████████████████| 391/391 [00:37<00:00, 10.53it/s] 

Test set: Average loss: 0.0043, Accuracy: 8391/10000 (83.91%)

Best accuracy: 83.91%
Epoch=147 Loss=0.5506 Batch_id=390 Accuracy=79.14 LR=0.031383: 100%|██████████████████████████████████████████████████████████| 391/391 [00:41<00:00,  9.34it/s] 

Test set: Average loss: 0.0050, Accuracy: 8223/10000 (82.23%)

Epoch=148 Loss=0.5858 Batch_id=390 Accuracy=79.14 LR=0.030346: 100%|██████████████████████████████████████████████████████████| 391/391 [00:43<00:00,  9.03it/s] 

Test set: Average loss: 0.0050, Accuracy: 8158/10000 (81.58%)

Epoch=149 Loss=0.4851 Batch_id=390 Accuracy=79.09 LR=0.029320: 100%|██████████████████████████████████████████████████████████| 391/391 [00:47<00:00,  8.19it/s] 

Test set: Average loss: 0.0048, Accuracy: 8202/10000 (82.02%)

Epoch=150 Loss=0.5830 Batch_id=390 Accuracy=79.10 LR=0.028304: 100%|██████████████████████████████████████████████████████████| 391/391 [00:48<00:00,  8.01it/s] 

Test set: Average loss: 0.0044, Accuracy: 8312/10000 (83.12%)

Epoch=151 Loss=0.7008 Batch_id=390 Accuracy=79.42 LR=0.027298: 100%|██████████████████████████████████████████████████████████| 391/391 [00:24<00:00, 16.12it/s] 

Test set: Average loss: 0.0042, Accuracy: 8395/10000 (83.95%)

Best accuracy: 83.95%
Epoch=152 Loss=0.5499 Batch_id=390 Accuracy=79.17 LR=0.026304: 100%|██████████████████████████████████████████████████████████| 391/391 [00:24<00:00, 16.08it/s] 

Test set: Average loss: 0.0049, Accuracy: 8230/10000 (82.30%)

Epoch=153 Loss=0.5712 Batch_id=390 Accuracy=79.78 LR=0.025322: 100%|██████████████████████████████████████████████████████████| 391/391 [00:24<00:00, 16.13it/s] 

Test set: Average loss: 0.0043, Accuracy: 8332/10000 (83.32%)

Epoch=154 Loss=0.4596 Batch_id=390 Accuracy=79.83 LR=0.024353: 100%|██████████████████████████████████████████████████████████| 391/391 [00:24<00:00, 16.12it/s] 

Test set: Average loss: 0.0046, Accuracy: 8307/10000 (83.07%)

Epoch=155 Loss=0.6637 Batch_id=390 Accuracy=79.72 LR=0.023396: 100%|██████████████████████████████████████████████████████████| 391/391 [00:24<00:00, 16.07it/s] 

Test set: Average loss: 0.0045, Accuracy: 8307/10000 (83.07%)

Epoch=156 Loss=0.5666 Batch_id=390 Accuracy=80.23 LR=0.022453: 100%|██████████████████████████████████████████████████████████| 391/391 [00:24<00:00, 16.14it/s] 

Test set: Average loss: 0.0040, Accuracy: 8433/10000 (84.33%)

Best accuracy: 84.33%
Epoch=157 Loss=0.6996 Batch_id=390 Accuracy=80.26 LR=0.021524: 100%|██████████████████████████████████████████████████████████| 391/391 [00:24<00:00, 16.13it/s] 

Test set: Average loss: 0.0042, Accuracy: 8383/10000 (83.83%)

Epoch=158 Loss=0.4299 Batch_id=390 Accuracy=80.20 LR=0.020609: 100%|██████████████████████████████████████████████████████████| 391/391 [00:24<00:00, 16.12it/s] 

Test set: Average loss: 0.0043, Accuracy: 8435/10000 (84.35%)

Best accuracy: 84.35%
Epoch=159 Loss=0.7843 Batch_id=390 Accuracy=79.89 LR=0.019709: 100%|██████████████████████████████████████████████████████████| 391/391 [00:24<00:00, 16.26it/s] 

Test set: Average loss: 0.0042, Accuracy: 8424/10000 (84.24%)

Epoch=160 Loss=0.5085 Batch_id=390 Accuracy=80.17 LR=0.018824: 100%|██████████████████████████████████████████████████████████| 391/391 [00:24<00:00, 16.13it/s] 

Test set: Average loss: 0.0048, Accuracy: 8227/10000 (82.27%)

Epoch=161 Loss=0.6060 Batch_id=390 Accuracy=80.29 LR=0.017954: 100%|██████████████████████████████████████████████████████████| 391/391 [00:24<00:00, 16.22it/s] 

Test set: Average loss: 0.0041, Accuracy: 8421/10000 (84.21%)

Epoch=162 Loss=0.5398 Batch_id=390 Accuracy=80.32 LR=0.017101: 100%|██████████████████████████████████████████████████████████| 391/391 [00:24<00:00, 16.25it/s] 

Test set: Average loss: 0.0042, Accuracy: 8446/10000 (84.46%)

Best accuracy: 84.46%
Epoch=163 Loss=0.5158 Batch_id=390 Accuracy=80.49 LR=0.016265: 100%|██████████████████████████████████████████████████████████| 391/391 [00:24<00:00, 16.21it/s] 

Test set: Average loss: 0.0042, Accuracy: 8445/10000 (84.45%)

Epoch=164 Loss=0.4973 Batch_id=390 Accuracy=80.35 LR=0.015445: 100%|██████████████████████████████████████████████████████████| 391/391 [00:24<00:00, 16.26it/s] 

Test set: Average loss: 0.0042, Accuracy: 8456/10000 (84.56%)

Best accuracy: 84.56%
Epoch=165 Loss=0.5164 Batch_id=390 Accuracy=80.76 LR=0.014643: 100%|██████████████████████████████████████████████████████████| 391/391 [00:24<00:00, 16.19it/s] 

Test set: Average loss: 0.0050, Accuracy: 8257/10000 (82.57%)

Epoch=166 Loss=0.7044 Batch_id=390 Accuracy=80.70 LR=0.013859: 100%|██████████████████████████████████████████████████████████| 391/391 [00:24<00:00, 16.27it/s] 

Test set: Average loss: 0.0044, Accuracy: 8352/10000 (83.52%)

Epoch=167 Loss=0.6527 Batch_id=390 Accuracy=81.08 LR=0.013092: 100%|██████████████████████████████████████████████████████████| 391/391 [00:24<00:00, 16.21it/s] 

Test set: Average loss: 0.0042, Accuracy: 8455/10000 (84.55%)

Epoch=168 Loss=0.4210 Batch_id=390 Accuracy=81.03 LR=0.012345: 100%|██████████████████████████████████████████████████████████| 391/391 [00:24<00:00, 16.25it/s] 

Test set: Average loss: 0.0039, Accuracy: 8509/10000 (85.09%)

Best accuracy: 85.09%
Epoch=169 Loss=0.3968 Batch_id=390 Accuracy=81.18 LR=0.011616: 100%|██████████████████████████████████████████████████████████| 391/391 [00:24<00:00, 16.25it/s] 

Test set: Average loss: 0.0038, Accuracy: 8518/10000 (85.18%)

Best accuracy: 85.18%
Epoch=170 Loss=0.7352 Batch_id=390 Accuracy=81.64 LR=0.010907: 100%|██████████████████████████████████████████████████████████| 391/391 [00:24<00:00, 16.29it/s] 

Test set: Average loss: 0.0043, Accuracy: 8392/10000 (83.92%)

Epoch=171 Loss=0.3765 Batch_id=390 Accuracy=81.34 LR=0.010217: 100%|██████████████████████████████████████████████████████████| 391/391 [00:24<00:00, 16.27it/s] 

Test set: Average loss: 0.0042, Accuracy: 8446/10000 (84.46%)

Epoch=172 Loss=0.5588 Batch_id=390 Accuracy=81.46 LR=0.009548: 100%|██████████████████████████████████████████████████████████| 391/391 [00:24<00:00, 16.26it/s] 

Test set: Average loss: 0.0040, Accuracy: 8507/10000 (85.07%)

Epoch=173 Loss=0.6192 Batch_id=390 Accuracy=81.97 LR=0.008899: 100%|██████████████████████████████████████████████████████████| 391/391 [00:24<00:00, 16.23it/s] 

Test set: Average loss: 0.0040, Accuracy: 8517/10000 (85.17%)

Epoch=174 Loss=0.6005 Batch_id=390 Accuracy=81.94 LR=0.008270: 100%|██████████████████████████████████████████████████████████| 391/391 [00:24<00:00, 16.23it/s] 

Test set: Average loss: 0.0040, Accuracy: 8523/10000 (85.23%)

Best accuracy: 85.23%
Epoch=175 Loss=0.4568 Batch_id=390 Accuracy=82.00 LR=0.007663: 100%|██████████████████████████████████████████████████████████| 391/391 [00:24<00:00, 16.26it/s] 

Test set: Average loss: 0.0041, Accuracy: 8510/10000 (85.10%)

Epoch=176 Loss=0.6008 Batch_id=390 Accuracy=82.11 LR=0.007076: 100%|██████████████████████████████████████████████████████████| 391/391 [00:24<00:00, 16.25it/s] 

Test set: Average loss: 0.0041, Accuracy: 8487/10000 (84.87%)

Epoch=177 Loss=0.6705 Batch_id=390 Accuracy=82.37 LR=0.006512: 100%|██████████████████████████████████████████████████████████| 391/391 [00:24<00:00, 16.26it/s] 

Test set: Average loss: 0.0043, Accuracy: 8467/10000 (84.67%)

Epoch=178 Loss=0.8934 Batch_id=390 Accuracy=82.32 LR=0.005969: 100%|██████████████████████████████████████████████████████████| 391/391 [00:24<00:00, 16.25it/s] 

Test set: Average loss: 0.0041, Accuracy: 8465/10000 (84.65%)

Epoch=179 Loss=0.6220 Batch_id=390 Accuracy=82.68 LR=0.005449: 100%|██████████████████████████████████████████████████████████| 391/391 [00:24<00:00, 16.25it/s] 


Epoch=179 Loss=0.6220 Batch_id=390 Accuracy=82.68 LR=0.005449: 100%|██████████████████████████████████████████████████████████| 391/391 [00:24<00:00, 16.25it/s] 

Epoch=179 Loss=0.6220 Batch_id=390 Accuracy=82.68 LR=0.005449: 100%|██████████████████████████████████████████████████████████| 391/391 [00:24<00:00, 16.25it/s] 


Test set: Average loss: 0.0040, Accuracy: 8563/10000 (85.63%)
Test set: Average loss: 0.0040, Accuracy: 8563/10000 (85.63%)

Best accuracy: 85.63%
Best accuracy: 85.63%
Epoch=180 Loss=0.4174 Batch_id=390 Accuracy=82.73 LR=0.004951: 100%|██████████████████████████████████████████████████████████| 391/391 [00:24<00:00, 16.28it/s] 
Epoch=180 Loss=0.4174 Batch_id=390 Accuracy=82.73 LR=0.004951: 100%|██████████████████████████████████████████████████████████| 391/391 [00:24<00:00, 16.28it/s] 

Test set: Average loss: 0.0040, Accuracy: 8561/10000 (85.61%)

Epoch=181 Loss=0.2495 Batch_id=390 Accuracy=82.67 LR=0.004475: 100%|██████████████████████████████████████████████████████████| 391/391 [00:24<00:00, 16.27it/s] 

Test set: Average loss: 0.0041, Accuracy: 8512/10000 (85.12%)

Epoch=182 Loss=0.4128 Batch_id=390 Accuracy=82.93 LR=0.004023: 100%|██████████████████████████████████████████████████████████| 391/391 [00:24<00:00, 16.24it/s] 

Test set: Average loss: 0.0037, Accuracy: 8605/10000 (86.05%)

Best accuracy: 86.05%
Epoch=183 Loss=0.4494 Batch_id=390 Accuracy=82.89 LR=0.003594: 100%|██████████████████████████████████████████████████████████| 391/391 [00:24<00:00, 16.02it/s] 

Test set: Average loss: 0.0040, Accuracy: 8562/10000 (85.62%)

Epoch=184 Loss=0.3932 Batch_id=390 Accuracy=83.30 LR=0.003188: 100%|██████████████████████████████████████████████████████████| 391/391 [00:24<00:00, 16.10it/s] 

Test set: Average loss: 0.0039, Accuracy: 8589/10000 (85.89%)

Epoch=185 Loss=0.3085 Batch_id=390 Accuracy=83.59 LR=0.002805: 100%|██████████████████████████████████████████████████████████| 391/391 [00:24<00:00, 16.12it/s] 

Test set: Average loss: 0.0039, Accuracy: 8595/10000 (85.95%)

Epoch=186 Loss=0.4371 Batch_id=390 Accuracy=83.82 LR=0.002447: 100%|██████████████████████████████████████████████████████████| 391/391 [00:24<00:00, 15.88it/s] 

Test set: Average loss: 0.0039, Accuracy: 8588/10000 (85.88%)

Epoch=187 Loss=0.3786 Batch_id=390 Accuracy=83.58 LR=0.002112: 100%|██████████████████████████████████████████████████████████| 391/391 [00:24<00:00, 16.00it/s]

Test set: Average loss: 0.0039, Accuracy: 8595/10000 (85.95%)

Epoch=188 Loss=0.5048 Batch_id=390 Accuracy=83.72 LR=0.001801: 100%|██████████████████████████████████████████████████████████| 391/391 [00:24<00:00, 16.07it/s]

Test set: Average loss: 0.0039, Accuracy: 8593/10000 (85.93%)

Epoch=189 Loss=0.4811 Batch_id=390 Accuracy=83.94 LR=0.001515: 100%|██████████████████████████████████████████████████████████| 391/391 [00:24<00:00, 15.86it/s] 

Test set: Average loss: 0.0039, Accuracy: 8616/10000 (86.16%)

Best accuracy: 86.16%
Epoch=190 Loss=0.5429 Batch_id=390 Accuracy=83.88 LR=0.001253: 100%|██████████████████████████████████████████████████████████| 391/391 [00:24<00:00, 16.19it/s] 

Test set: Average loss: 0.0040, Accuracy: 8584/10000 (85.84%)

Epoch=191 Loss=0.4555 Batch_id=390 Accuracy=84.09 LR=0.001016: 100%|██████████████████████████████████████████████████████████| 391/391 [00:24<00:00, 16.18it/s] 

Test set: Average loss: 0.0038, Accuracy: 8640/10000 (86.40%)

Best accuracy: 86.40%
Epoch=192 Loss=0.3741 Batch_id=390 Accuracy=83.94 LR=0.000803: 100%|██████████████████████████████████████████████████████████| 391/391 [00:24<00:00, 16.16it/s] 

Test set: Average loss: 0.0039, Accuracy: 8607/10000 (86.07%)

Epoch=193 Loss=0.5019 Batch_id=390 Accuracy=84.11 LR=0.000616: 100%|██████████████████████████████████████████████████████████| 391/391 [00:24<00:00, 16.17it/s] 

Test set: Average loss: 0.0038, Accuracy: 8631/10000 (86.31%)

Epoch=194 Loss=0.5989 Batch_id=390 Accuracy=84.26 LR=0.000453: 100%|██████████████████████████████████████████████████████████| 391/391 [00:24<00:00, 16.28it/s] 

Test set: Average loss: 0.0039, Accuracy: 8620/10000 (86.20%)

Epoch=195 Loss=0.3143 Batch_id=390 Accuracy=84.13 LR=0.000314: 100%|██████████████████████████████████████████████████████████| 391/391 [00:23<00:00, 16.32it/s] 

Test set: Average loss: 0.0039, Accuracy: 8628/10000 (86.28%)

Epoch=196 Loss=0.5010 Batch_id=390 Accuracy=84.40 LR=0.000201: 100%|██████████████████████████████████████████████████████████| 391/391 [00:24<00:00, 16.29it/s] 

Test set: Average loss: 0.0039, Accuracy: 8624/10000 (86.24%)

Epoch=197 Loss=0.4254 Batch_id=390 Accuracy=84.26 LR=0.000113: 100%|██████████████████████████████████████████████████████████| 391/391 [00:24<00:00, 16.24it/s] 

Test set: Average loss: 0.0039, Accuracy: 8618/10000 (86.18%)

Epoch=198 Loss=0.4971 Batch_id=390 Accuracy=84.52 LR=0.000051: 100%|██████████████████████████████████████████████████████████| 391/391 [00:23<00:00, 16.31it/s] 

Test set: Average loss: 0.0039, Accuracy: 8623/10000 (86.23%)

Epoch=199 Loss=0.3090 Batch_id=390 Accuracy=84.34 LR=0.000013: 100%|██████████████████████████████████████████████████████████| 391/391 [00:24<00:00, 16.19it/s] 

Test set: Average loss: 0.0039, Accuracy: 8622/10000 (86.22%)

Epoch=200 Loss=0.3697 Batch_id=390 Accuracy=84.57 LR=0.000000:  100%|██████████████████████████████████████████████████████████| 391/391 [00:24<00:00, 15.78it/s] 

Test set: Average loss: 0.0039, Accuracy: 8610/10000 (86.10%)
